{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Library Imports\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from model_creators.xgboost_model import XGBModel\n",
    "from model_creators.catboost_model import CatModel\n",
    "from model_creators.lgbm_model import LGBMModel\n",
    "from model_creators.histgbm_model import HistGBMModel\n",
    "from model_creators.gbm_model import GBMModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters\n",
    "seed = 7\n",
    "\n",
    "### Model training\n",
    "model_list = ['xgboost', 'catboost', 'lgbm', 'gbm', 'histgbm']    # Options include 'xgboost', 'catboost', 'lgbm', 'gbm', 'histgbm'\n",
    "cross_validation_strat = KFold(n_splits=5, shuffle=True, random_state=seed)    # See ReadMe.md for more information\n",
    "USE_ENSEMBLE = False    # If False, will only use best model\n",
    "metric = 'accuracy'\n",
    "\n",
    "### Logging\n",
    "USE_LOGGER = False\n",
    "LOG_FILE = ''\n",
    "\n",
    "\n",
    "### Data\n",
    "target_col = 'Transported'\n",
    "data_filename = './data/train-cleaned.csv'\n",
    "validation_size = 0.1\n",
    "\n",
    "\n",
    "### Model eval\n",
    "validation_accuracy = []\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Earth</th>\n",
       "      <th>Europa</th>\n",
       "      <th>Mars</th>\n",
       "      <th>55 Cancri e</th>\n",
       "      <th>PSO J318.5-22</th>\n",
       "      <th>TRAPPIST-1e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CryoSleep   Age  VIP  RoomService  FoodCourt  ShoppingMall     Spa  VRDeck   \n",
       "0          0  39.0    0          0.0        0.0           0.0     0.0     0.0  \\\n",
       "1          0  24.0    0        109.0        9.0          25.0   549.0    44.0   \n",
       "2          0  58.0    1         43.0     3576.0           0.0  6715.0    49.0   \n",
       "3          0  33.0    0          0.0     1283.0         371.0  3329.0   193.0   \n",
       "4          0  16.0    0        303.0       70.0         151.0   565.0     2.0   \n",
       "\n",
       "   Transported  Earth  Europa  Mars  55 Cancri e  PSO J318.5-22  TRAPPIST-1e  \n",
       "0            0    0.0     1.0   0.0          0.0            0.0          1.0  \n",
       "1            1    1.0     0.0   0.0          0.0            0.0          1.0  \n",
       "2            0    0.0     1.0   0.0          0.0            0.0          1.0  \n",
       "3            0    0.0     1.0   0.0          0.0            0.0          1.0  \n",
       "4            1    1.0     0.0   0.0          0.0            0.0          1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Load data\n",
    "\n",
    "df = pd.read_csv(data_filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (7823, 15)\n",
      "Test size: (870, 15)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train/test \n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=validation_size, random_state=seed)\n",
    "print(f\"Train size: {train_df.shape}\\nTest size: {val_df.shape}\")\n",
    "\n",
    "train_x, train_y = train_df.drop(target_col, axis=1), train_df[target_col]\n",
    "val_x, val_y = val_df.drop(target_col, axis=1), val_df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-17 04:12:55,207] A new study created in memory with name: no-name-e27c1d23-b251-4137-bfec-3c73e12404eb\n",
      "[I 2023-08-17 04:13:01,720] Trial 0 finished with value: 0.7908724250917202 and parameters: {'max_depth': 5, 'subsample': 0.7, 'n_estimators': 3225, 'eta': 0.05, 'reg_alpha': 40, 'reg_lambda': 32, 'min_child_weight': 12, 'colsample_bytree': 0.6250347718011828}. Best is trial 0 with value: 0.7908724250917202.\n",
      "[I 2023-08-17 04:13:05,506] Trial 1 finished with value: 0.7851200738664684 and parameters: {'max_depth': 12, 'subsample': 0.95, 'n_estimators': 2950, 'eta': 0.03, 'reg_alpha': 48, 'reg_lambda': 27, 'min_child_weight': 16, 'colsample_bytree': 0.22187708928700178}. Best is trial 0 with value: 0.7908724250917202.\n",
      "[I 2023-08-17 04:13:11,456] Trial 2 finished with value: 0.7920228299682146 and parameters: {'max_depth': 9, 'subsample': 0.7, 'n_estimators': 3575, 'eta': 0.09999999999999999, 'reg_alpha': 24, 'reg_lambda': 13, 'min_child_weight': 20, 'colsample_bytree': 0.35758644869370126}. Best is trial 2 with value: 0.7920228299682146.\n",
      "[I 2023-08-17 04:13:15,611] Trial 3 finished with value: 0.7892109198172949 and parameters: {'max_depth': 7, 'subsample': 0.95, 'n_estimators': 650, 'eta': 0.01, 'reg_alpha': 41, 'reg_lambda': 37, 'min_child_weight': 17, 'colsample_bytree': 0.7641886803037806}. Best is trial 2 with value: 0.7920228299682146.\n",
      "[I 2023-08-17 04:13:19,835] Trial 4 finished with value: 0.7906169974587973 and parameters: {'max_depth': 14, 'subsample': 0.7, 'n_estimators': 1900, 'eta': 0.060000000000000005, 'reg_alpha': 30, 'reg_lambda': 21, 'min_child_weight': 13, 'colsample_bytree': 0.4075653360062438}. Best is trial 2 with value: 0.7920228299682146.\n",
      "[I 2023-08-17 04:13:28,360] Trial 5 finished with value: 0.7925338486554504 and parameters: {'max_depth': 14, 'subsample': 0.75, 'n_estimators': 4450, 'eta': 0.09, 'reg_alpha': 20, 'reg_lambda': 84, 'min_child_weight': 19, 'colsample_bytree': 0.3918405792294599}. Best is trial 5 with value: 0.7925338486554504.\n",
      "[I 2023-08-17 04:13:30,408] Trial 6 finished with value: 0.7917670754925112 and parameters: {'max_depth': 7, 'subsample': 0.6, 'n_estimators': 900, 'eta': 0.05, 'reg_alpha': 41, 'reg_lambda': 30, 'min_child_weight': 13, 'colsample_bytree': 0.7456872049992324}. Best is trial 5 with value: 0.7925338486554504.\n",
      "[I 2023-08-17 04:13:35,471] Trial 7 finished with value: 0.7876752490133434 and parameters: {'max_depth': 9, 'subsample': 0.65, 'n_estimators': 4925, 'eta': 0.09999999999999999, 'reg_alpha': 5, 'reg_lambda': 71, 'min_child_weight': 8, 'colsample_bytree': 0.12536475565039695}. Best is trial 5 with value: 0.7925338486554504.\n",
      "[I 2023-08-17 04:13:41,573] Trial 8 finished with value: 0.7934293978738877 and parameters: {'max_depth': 2, 'subsample': 0.6, 'n_estimators': 3600, 'eta': 0.060000000000000005, 'reg_alpha': 12, 'reg_lambda': 17, 'min_child_weight': 15, 'colsample_bytree': 0.7129457493231419}. Best is trial 8 with value: 0.7934293978738877.\n",
      "[I 2023-08-17 04:13:52,402] Trial 9 finished with value: 0.7950903311734473 and parameters: {'max_depth': 10, 'subsample': 0.6, 'n_estimators': 4150, 'eta': 0.04, 'reg_alpha': 25, 'reg_lambda': 37, 'min_child_weight': 7, 'colsample_bytree': 0.8431320119175758}. Best is trial 9 with value: 0.7950903311734473.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model params: \n",
      "{'max_depth': 10, 'subsample': 0.6, 'n_estimators': 4150, 'eta': 0.04, 'reg_alpha': 25, 'reg_lambda': 37, 'min_child_weight': 7, 'colsample_bytree': 0.8431320119175758}\n",
      "XGBoost Validation Accuracy: 0.8091954022988506\n"
     ]
    }
   ],
   "source": [
    "# Train XGB model\n",
    "if 'xgboost' in model_list:\n",
    "    xgb_model = XGBModel(train_x, train_y, cross_validation_strat)\n",
    "    xgb_model.run_trial(n_trials=10)\n",
    "\n",
    "    print(\"Best model params: \")\n",
    "    best_params = xgb_model.get_best_params()\n",
    "    print(best_params)\n",
    "\n",
    "    # Evaluate model accuracy\n",
    "    best_params['xgboost'] = best_params\n",
    "    best_xgb = xgb_model.get_best_model()\n",
    "    xgb_preds = best_xgb.predict(val_x)\n",
    "    xgb_acc = accuracy_score(val_y, xgb_preds)\n",
    "    print(f\"XGBoost Validation Accuracy: {xgb_acc}\")\n",
    "    validation_accuracy.append(xgb_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-17 04:13:57,827] A new study created in memory with name: no-name-43ad3119-f521-4283-9a63-0fe4b46989c9\n",
      "[I 2023-08-17 04:14:15,901] Trial 0 finished with value: 0.7855043592655843 and parameters: {'max_depth': 5, 'subsample': 1.0, 'n_estimators': 4725, 'eta': 0.04, 'reg_lambda': 31}. Best is trial 0 with value: 0.7855043592655843.\n",
      "[I 2023-08-17 04:14:29,254] Trial 1 finished with value: 0.794195435640571 and parameters: {'max_depth': 2, 'subsample': 0.6, 'n_estimators': 4650, 'eta': 0.01, 'reg_lambda': 80}. Best is trial 1 with value: 0.794195435640571.\n",
      "[I 2023-08-17 04:14:31,623] Trial 2 finished with value: 0.7950903311734473 and parameters: {'max_depth': 6, 'subsample': 0.75, 'n_estimators': 325, 'eta': 0.05, 'reg_lambda': 95}. Best is trial 2 with value: 0.7950903311734473.\n",
      "[I 2023-08-17 04:14:33,021] Trial 3 finished with value: 0.7885715336280366 and parameters: {'max_depth': 7, 'subsample': 1.0, 'n_estimators': 175, 'eta': 0.01, 'reg_lambda': 20}. Best is trial 2 with value: 0.7950903311734473.\n",
      "[I 2023-08-17 04:33:10,132] Trial 4 finished with value: 0.7853773808453788 and parameters: {'max_depth': 15, 'subsample': 0.65, 'n_estimators': 1000, 'eta': 0.08, 'reg_lambda': 75}. Best is trial 2 with value: 0.7950903311734473.\n",
      "[I 2023-08-17 04:35:01,757] Trial 5 finished with value: 0.7918948710196678 and parameters: {'max_depth': 11, 'subsample': 0.95, 'n_estimators': 1425, 'eta': 0.05, 'reg_lambda': 75}. Best is trial 2 with value: 0.7950903311734473.\n",
      "[I 2023-08-17 04:37:42,041] Trial 6 finished with value: 0.7819251039768595 and parameters: {'max_depth': 10, 'subsample': 0.65, 'n_estimators': 4275, 'eta': 0.03, 'reg_lambda': 31}. Best is trial 2 with value: 0.7950903311734473.\n",
      "[I 2023-08-17 04:42:13,265] Trial 7 finished with value: 0.7917691999705843 and parameters: {'max_depth': 14, 'subsample': 0.8, 'n_estimators': 475, 'eta': 0.09999999999999999, 'reg_lambda': 99}. Best is trial 2 with value: 0.7950903311734473.\n",
      "[I 2023-08-17 04:51:26,935] Trial 8 finished with value: 0.7800073539625602 and parameters: {'max_depth': 14, 'subsample': 1.0, 'n_estimators': 950, 'eta': 0.06999999999999999, 'reg_lambda': 8}. Best is trial 2 with value: 0.7950903311734473.\n",
      "[I 2023-08-17 04:51:33,144] Trial 9 finished with value: 0.7957296356520105 and parameters: {'max_depth': 3, 'subsample': 0.8, 'n_estimators': 1800, 'eta': 0.09, 'reg_lambda': 95}. Best is trial 9 with value: 0.7957296356520105.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model params: \n",
      "{'max_depth': 3, 'subsample': 0.8, 'n_estimators': 1800, 'eta': 0.09, 'reg_lambda': 95}\n",
      "CatBoost Validation Accuracy: 0.7931034482758621\n"
     ]
    }
   ],
   "source": [
    "# Train CatBoost model\n",
    "if 'catboost' in model_list:\n",
    "    cat_model = CatModel(train_x, train_y, cross_validation_strat)\n",
    "    cat_model.run_trial(n_trials=10)\n",
    "\n",
    "    print(\"Best model params: \")\n",
    "    best_params = cat_model.get_best_params()\n",
    "    print(best_params)\n",
    "\n",
    "    # Evaluate model accuracy\n",
    "    best_params['catboost'] = best_params\n",
    "    best_cat = cat_model.get_best_model()\n",
    "    cat_preds = best_cat.predict(val_x)\n",
    "    cat_acc = accuracy_score(val_y, cat_preds)\n",
    "    print(f\"CatBoost Validation Accuracy: {cat_acc}\")\n",
    "    validation_accuracy.append(cat_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-17 04:51:36,881] A new study created in memory with name: no-name-44cc9ea1-e68e-460d-a482-4d0c506d18a0\n",
      "[I 2023-08-17 04:51:38,589] Trial 0 finished with value: 0.7935567848475688 and parameters: {'max_depth': 8, 'subsample': 0.8, 'n_estimators': 3325, 'eta': 0.09, 'reg_lambda': 24, 'reg_alpha': 16, 'min_child_weight': 19, 'colsample_bytree': 0.6739765076795549}. Best is trial 0 with value: 0.7935567848475688.\n",
      "[I 2023-08-17 04:51:40,242] Trial 1 finished with value: 0.7894663474502177 and parameters: {'max_depth': 10, 'subsample': 0.7, 'n_estimators': 3500, 'eta': 0.09, 'reg_lambda': 70, 'reg_alpha': 33, 'min_child_weight': 20, 'colsample_bytree': 0.8141207423691543}. Best is trial 0 with value: 0.7935567848475688.\n",
      "[I 2023-08-17 04:51:41,101] Trial 2 finished with value: 0.7840972193850453 and parameters: {'max_depth': 8, 'subsample': 0.8, 'n_estimators': 300, 'eta': 0.09999999999999999, 'reg_lambda': 94, 'reg_alpha': 46, 'min_child_weight': 11, 'colsample_bytree': 0.3218789944678385}. Best is trial 0 with value: 0.7935567848475688.\n",
      "[I 2023-08-17 04:51:41,914] Trial 3 finished with value: 0.7826911417435428 and parameters: {'max_depth': 9, 'subsample': 0.75, 'n_estimators': 2150, 'eta': 0.09, 'reg_lambda': 24, 'reg_alpha': 36, 'min_child_weight': 12, 'colsample_bytree': 0.11104377586654522}. Best is trial 0 with value: 0.7935567848475688.\n",
      "[I 2023-08-17 04:51:42,478] Trial 4 finished with value: 0.789849407188907 and parameters: {'max_depth': 15, 'subsample': 1.0, 'n_estimators': 1650, 'eta': 0.06999999999999999, 'reg_lambda': 86, 'reg_alpha': 16, 'min_child_weight': 20, 'colsample_bytree': 0.680010412549638}. Best is trial 0 with value: 0.7935567848475688.\n",
      "[I 2023-08-17 04:51:43,126] Trial 5 finished with value: 0.7915113210168079 and parameters: {'max_depth': 11, 'subsample': 1.0, 'n_estimators': 2375, 'eta': 0.09999999999999999, 'reg_lambda': 75, 'reg_alpha': 21, 'min_child_weight': 19, 'colsample_bytree': 0.5557900206457712}. Best is trial 0 with value: 0.7935567848475688.\n",
      "[I 2023-08-17 04:51:44,660] Trial 6 finished with value: 0.7921504620739809 and parameters: {'max_depth': 7, 'subsample': 0.6, 'n_estimators': 4125, 'eta': 0.05, 'reg_lambda': 85, 'reg_alpha': 10, 'min_child_weight': 11, 'colsample_bytree': 0.6718641672190592}. Best is trial 0 with value: 0.7935567848475688.\n",
      "[I 2023-08-17 04:51:45,318] Trial 7 finished with value: 0.7870380690128531 and parameters: {'max_depth': 9, 'subsample': 1.0, 'n_estimators': 1925, 'eta': 0.09, 'reg_lambda': 27, 'reg_alpha': 38, 'min_child_weight': 19, 'colsample_bytree': 0.3481990776584535}. Best is trial 0 with value: 0.7935567848475688.\n",
      "[I 2023-08-17 04:51:46,767] Trial 8 finished with value: 0.7876759026989042 and parameters: {'max_depth': 8, 'subsample': 0.85, 'n_estimators': 4225, 'eta': 0.060000000000000005, 'reg_lambda': 61, 'reg_alpha': 23, 'min_child_weight': 3, 'colsample_bytree': 0.13086007429203847}. Best is trial 0 with value: 0.7935567848475688.\n",
      "[I 2023-08-17 04:51:46,907] Trial 9 finished with value: 0.7949625356462907 and parameters: {'max_depth': 13, 'subsample': 0.6, 'n_estimators': 150, 'eta': 0.060000000000000005, 'reg_lambda': 43, 'reg_alpha': 4, 'min_child_weight': 19, 'colsample_bytree': 0.6885190059844645}. Best is trial 9 with value: 0.7949625356462907.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model params: \n",
      "{'max_depth': 13, 'subsample': 0.6, 'n_estimators': 150, 'eta': 0.060000000000000005, 'reg_lambda': 43, 'reg_alpha': 4, 'min_child_weight': 19, 'colsample_bytree': 0.6885190059844645}\n",
      "[LightGBM] [Warning] learning_rate is set=0.1, eta=0.060000000000000005 will be ignored. Current value: learning_rate=0.1\n",
      "LGBMBoost Validation Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Train LightGBM model\n",
    "if 'lgbm' in model_list:\n",
    "    lgbm_model = LGBMModel(train_x, train_y, cross_validation_strat)\n",
    "    lgbm_model.run_trial(n_trials=10)\n",
    "\n",
    "    print(\"Best model params: \")\n",
    "    best_params = lgbm_model.get_best_params()\n",
    "    print(best_params)\n",
    "\n",
    "    # Evaluate model accuracy\n",
    "    best_params['lgbm'] = best_params\n",
    "    best_lgbm = lgbm_model.get_best_model()\n",
    "    lgbm_preds = best_lgbm.predict(val_x)\n",
    "    lgbm_acc = accuracy_score(val_y, lgbm_preds)\n",
    "    print(f\"LGBMBoost Validation Accuracy: {lgbm_acc}\")\n",
    "    validation_accuracy.append(lgbm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-17 04:51:47,073] A new study created in memory with name: no-name-46885158-bae7-44f7-9f2a-d7232dd4e7c9\n",
      "c:\\Users\\Saqi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [2, 255] and step=5, but the range is not divisible by `step`. It will be replaced by [2, 252].\n",
      "  warnings.warn(\n",
      "[I 2023-08-17 04:51:47,835] Trial 0 finished with value: 0.7823088991118047 and parameters: {'max_iter': 550, 'learning_rate': 0.38, 'max_bins': 122, 'max_depth': 3, 'l2_regularization': 3.1}. Best is trial 0 with value: 0.7823088991118047.\n",
      "[I 2023-08-17 04:51:57,422] Trial 1 finished with value: 0.7585339467082846 and parameters: {'max_iter': 3475, 'learning_rate': 0.24000000000000002, 'max_bins': 157, 'max_depth': 15, 'l2_regularization': 0.5}. Best is trial 0 with value: 0.7823088991118047.\n",
      "[I 2023-08-17 04:52:09,323] Trial 2 finished with value: 0.7550817515504604 and parameters: {'max_iter': 4825, 'learning_rate': 0.31, 'max_bins': 32, 'max_depth': 13, 'l2_regularization': 1.8000000000000003}. Best is trial 0 with value: 0.7823088991118047.\n",
      "[I 2023-08-17 04:52:16,950] Trial 3 finished with value: 0.7608343479077977 and parameters: {'max_iter': 2900, 'learning_rate': 0.27, 'max_bins': 252, 'max_depth': 7, 'l2_regularization': 1.2000000000000002}. Best is trial 0 with value: 0.7823088991118047.\n",
      "[I 2023-08-17 04:52:17,784] Trial 4 finished with value: 0.7645406633274229 and parameters: {'max_iter': 325, 'learning_rate': 0.89, 'max_bins': 192, 'max_depth': 6, 'l2_regularization': 3.5000000000000004}. Best is trial 0 with value: 0.7823088991118047.\n",
      "[I 2023-08-17 04:52:22,461] Trial 5 finished with value: 0.7630092414796172 and parameters: {'max_iter': 4300, 'learning_rate': 0.54, 'max_bins': 117, 'max_depth': 3, 'l2_regularization': 3.3000000000000003}. Best is trial 0 with value: 0.7823088991118047.\n",
      "[I 2023-08-17 04:52:29,289] Trial 6 finished with value: 0.7296420254447105 and parameters: {'max_iter': 3350, 'learning_rate': 0.61, 'max_bins': 2, 'max_depth': 5, 'l2_regularization': 0.30000000000000004}. Best is trial 0 with value: 0.7823088991118047.\n",
      "[I 2023-08-17 04:52:34,740] Trial 7 finished with value: 0.7590449653955207 and parameters: {'max_iter': 1975, 'learning_rate': 0.39, 'max_bins': 197, 'max_depth': 9, 'l2_regularization': 2.6}. Best is trial 0 with value: 0.7823088991118047.\n",
      "[I 2023-08-17 04:52:40,855] Trial 8 finished with value: 0.7520138417917521 and parameters: {'max_iter': 2500, 'learning_rate': 0.85, 'max_bins': 17, 'max_depth': 12, 'l2_regularization': 3.1}. Best is trial 0 with value: 0.7823088991118047.\n",
      "[I 2023-08-17 04:52:46,911] Trial 9 finished with value: 0.7516304552102824 and parameters: {'max_iter': 4175, 'learning_rate': 0.62, 'max_bins': 92, 'max_depth': 4, 'l2_regularization': 1.9000000000000001}. Best is trial 0 with value: 0.7823088991118047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model params: \n",
      "{'max_iter': 550, 'learning_rate': 0.38, 'max_bins': 122, 'max_depth': 3, 'l2_regularization': 3.1}\n",
      "HistGBM Validation Accuracy: 0.7954022988505747\n"
     ]
    }
   ],
   "source": [
    "# Train HistGBM model\n",
    "if 'histgbm' in model_list:\n",
    "    hist_model = HistGBMModel(train_x, train_y, cross_validation_strat)\n",
    "    hist_model.run_trial(n_trials=10)\n",
    "\n",
    "    print(\"Best model params: \")\n",
    "    best_params = hist_model.get_best_params()\n",
    "    print(best_params)\n",
    "\n",
    "    # Evaluate model accuracy\n",
    "    best_params['histgbm'] = best_params\n",
    "    best_hist = hist_model.get_best_model()\n",
    "    hist_preds = best_hist.predict(val_x)\n",
    "    hist_acc = accuracy_score(val_y, hist_preds)\n",
    "    print(f\"HistGBM Validation Accuracy: {hist_acc}\")\n",
    "    validation_accuracy.append(hist_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-17 04:52:47,683] A new study created in memory with name: no-name-5868c6df-e042-4020-98f1-df7c02b7cf80\n",
      "[I 2023-08-17 04:54:11,547] Trial 0 finished with value: 0.7733613328648588 and parameters: {'max_depth': 9, 'subsample': 0.9, 'n_estimators': 4075, 'learning_rate': 0.01}. Best is trial 0 with value: 0.7733613328648588.\n",
      "[I 2023-08-17 04:54:29,616] Trial 1 finished with value: 0.7847388934737667 and parameters: {'max_depth': 5, 'subsample': 0.65, 'n_estimators': 2250, 'learning_rate': 0.02}. Best is trial 1 with value: 0.7847388934737667.\n",
      "[I 2023-08-17 04:54:45,195] Trial 2 finished with value: 0.7878043519116218 and parameters: {'max_depth': 2, 'subsample': 0.6, 'n_estimators': 4100, 'learning_rate': 0.060000000000000005}. Best is trial 2 with value: 0.7878043519116218.\n",
      "[I 2023-08-17 04:55:07,239] Trial 3 finished with value: 0.7725942328591391 and parameters: {'max_depth': 11, 'subsample': 0.9, 'n_estimators': 800, 'learning_rate': 0.09}. Best is trial 2 with value: 0.7878043519116218.\n",
      "[I 2023-08-17 04:55:23,059] Trial 4 finished with value: 0.7924069519459402 and parameters: {'max_depth': 4, 'subsample': 0.65, 'n_estimators': 2400, 'learning_rate': 0.01}. Best is trial 4 with value: 0.7924069519459402.\n",
      "[I 2023-08-17 04:56:03,068] Trial 5 finished with value: 0.7686323263852006 and parameters: {'max_depth': 7, 'subsample': 0.65, 'n_estimators': 3500, 'learning_rate': 0.06999999999999999}. Best is trial 4 with value: 0.7924069519459402.\n",
      "[I 2023-08-17 04:56:59,369] Trial 6 finished with value: 0.7687596316481865 and parameters: {'max_depth': 10, 'subsample': 0.65, 'n_estimators': 2950, 'learning_rate': 0.04}. Best is trial 4 with value: 0.7924069519459402.\n",
      "[I 2023-08-17 04:57:59,792] Trial 7 finished with value: 0.7630067084480687 and parameters: {'max_depth': 10, 'subsample': 0.75, 'n_estimators': 3000, 'learning_rate': 0.08}. Best is trial 4 with value: 0.7924069519459402.\n",
      "[I 2023-08-17 04:59:54,024] Trial 8 finished with value: 0.7713163592982686 and parameters: {'max_depth': 15, 'subsample': 0.75, 'n_estimators': 2925, 'learning_rate': 0.02}. Best is trial 4 with value: 0.7924069519459402.\n",
      "[I 2023-08-17 04:59:55,044] Trial 9 finished with value: 0.7924067068138549 and parameters: {'max_depth': 4, 'subsample': 0.9, 'n_estimators': 125, 'learning_rate': 0.03}. Best is trial 4 with value: 0.7924069519459402.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model params: \n",
      "{'max_depth': 4, 'subsample': 0.65, 'n_estimators': 2400, 'learning_rate': 0.01}\n",
      "GBM Validation Accuracy: 0.8045977011494253\n"
     ]
    }
   ],
   "source": [
    "# Train GBM model\n",
    "if 'gbm' in model_list:\n",
    "    gbm_model = GBMModel(train_x, train_y, cross_validation_strat)\n",
    "    gbm_model.run_trial(n_trials=10)\n",
    "\n",
    "    print(\"Best model params: \")\n",
    "    best_params = gbm_model.get_best_params()\n",
    "    print(best_params)\n",
    "\n",
    "    # Evaluate model accuracy\n",
    "    best_params['gbm'] = best_params\n",
    "    best_gbm = gbm_model.get_best_model()\n",
    "    gbm_preds = best_gbm.predict(val_x)\n",
    "    gbm_acc = accuracy_score(val_y, gbm_preds)\n",
    "    print(f\"GBM Validation Accuracy: {gbm_acc}\")\n",
    "    validation_accuracy.append(gbm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------  --------\n",
      "xgboost   0.809195\n",
      "catboost  0.793103\n",
      "lgbm      0.8\n",
      "gbm       0.795402\n",
      "histgbm   0.804598\n",
      "--------  --------\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(zip(model_list, validation_accuracy)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e084279891f6f4db1ee843a72e2e91611a252795aeda8ffc8cf83a1802c1e7e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
